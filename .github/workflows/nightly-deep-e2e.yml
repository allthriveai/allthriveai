name: Nightly E2E Tests (Full Suite)

# Run nightly at 2 AM UTC (9 PM EST), or manually trigger
on:
  schedule:
    - cron: '0 2 * * *'  # 2 AM UTC daily
  workflow_dispatch:
    inputs:
      test_suite:
        description: 'Test suite to run'
        required: false
        default: 'all'
        type: choice
        options:
          - all
          - standard
          - deep-all
          - deep-chat
          - deep-battles
          - deep-learning
          - deep-community

# Only allow one nightly run at a time
concurrency:
  group: nightly-deep-e2e
  cancel-in-progress: true

jobs:
  nightly-e2e-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 90  # 1.5 hours for full suite (standard + deep)

    services:
      postgres:
        image: postgres:18-alpine
        env:
          POSTGRES_DB: allthrive_ai
          POSTGRES_USER: allthrive
          POSTGRES_PASSWORD: allthrive
        ports:
          - 5432:5432
        options: >-
          --health-cmd "pg_isready -U allthrive -d allthrive_ai"
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 5s
          --health-timeout 5s
          --health-retries 5

    env:
      # Django configuration
      DATABASE_URL: postgresql://allthrive:allthrive@localhost:5432/allthrive_ai
      SECRET_KEY: nightly-test-secret-key
      DEBUG: "False"
      SECURE_SSL_REDIRECT: "False"
      ALLOWED_HOSTS: "localhost,127.0.0.1"
      CORS_ALLOWED_ORIGINS: "http://localhost:3000,http://127.0.0.1:3000"
      PYTHONUNBUFFERED: "1"
      # Redis
      REDIS_URL: redis://localhost:6379/0
      CACHE_URL: redis://localhost:6379/2
      CELERY_BROKER_URL: redis://localhost:6379/0
      CELERY_RESULT_BACKEND: redis://localhost:6379/0
      # Auth
      COOKIE_DOMAIN: ""
      CSRF_TRUSTED_ORIGINS: "http://localhost:3000,http://127.0.0.1:3000"
      # AI Configuration - Use Azure OpenAI for CI/CD (production uses OpenAI directly)
      DEFAULT_AI_PROVIDER: "azure"
      AZURE_OPENAI_API_KEY: ${{ secrets.AZURE_OPENAI_API_KEY }}
      AZURE_OPENAI_ENDPOINT: ${{ secrets.AZURE_OPENAI_ENDPOINT }}
      AZURE_OPENAI_DEPLOYMENT_NAME: ${{ secrets.AZURE_OPENAI_DEPLOYMENT_NAME }}
      # Anthropic for Claude-specific features
      ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
      # OpenAI for DALL-E image generation (Azure doesn't have this)
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      # Deep E2E flag
      RUN_DEEP_E2E: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: 'requirements.txt'

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'frontend/package-lock.json'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Node dependencies
        working-directory: frontend
        run: npm ci

      - name: Install Playwright browsers
        working-directory: frontend
        run: npx playwright install --with-deps chromium

      - name: Wait for Postgres
        run: |
          python - <<'PY'
          import os, time, psycopg2
          url = os.environ['DATABASE_URL']
          for i in range(60):
              try:
                  psycopg2.connect(url).close()
                  print('DB ready')
                  break
              except Exception as e:
                  print('Waiting for DB...', e)
                  time.sleep(1)
          else:
              raise SystemExit('Database not available')
          PY

      - name: Setup database
        run: |
          python manage.py migrate --noinput
          python manage.py create_test_users --quiet || true

      - name: Start backend server
        run: |
          python manage.py runserver 8000 &
          sleep 10
          curl -f http://localhost:8000/api/v1/health/ || echo "Backend health check failed"
        env:
          DJANGO_SETTINGS_MODULE: config.settings

      - name: Start Celery worker and run integration tests
        run: |
          # Start Celery worker in background
          celery -A config worker --loglevel=info > /tmp/celery.log 2>&1 &
          echo $! > /tmp/celery.pid

          # Wait for worker to be ready
          for i in {1..30}; do
            if grep -q "ready" /tmp/celery.log 2>/dev/null; then
              echo "✅ Celery worker started"
              break
            fi
            echo "Waiting for Celery worker... ($i/30)"
            sleep 1
          done

          # Run comprehensive Celery integration tests
          python - <<'PY'
          import sys
          import os
          import time

          # CRITICAL: Set up Django BEFORE importing any task modules
          # Task modules import Django models which require the app registry to be ready
          os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'config.settings')
          import django
          django.setup()

          print("=" * 60)
          print("CELERY INTEGRATION TESTS")
          print("=" * 60)

          # Test 1: Basic health check
          print("\n[Test 1] Basic health check task...")
          from config.celery import health_check
          try:
              result = health_check.apply_async()
              response = result.get(timeout=10)
              assert response.get('status') == 'healthy', f"Unexpected: {response}"
              print("  ✅ Health check passed")
          except Exception as e:
              print(f"  ❌ Health check failed: {e}")
              sys.exit(1)

          # Test 2: Verify task discovery
          print("\n[Test 2] Task discovery verification...")
          from config.celery import app

          # Force task discovery by importing task modules
          # (autodiscover_tasks runs on import, not on app creation)
          import core.battles.tasks
          import core.billing.tasks
          import core.notifications.tasks

          registered_tasks = list(app.tasks.keys())
          critical_tasks = [
              'core.battles.tasks.generate_submission_image_task',
              'core.battles.tasks.cleanup_stale_battles',
              'core.billing.tasks.reset_monthly_ai_requests_task',
          ]
          missing = [t for t in critical_tasks if t not in registered_tasks]
          if missing:
              print(f"  ❌ Missing critical tasks: {missing}")
              sys.exit(1)
          print(f"  ✅ All {len(critical_tasks)} critical tasks discovered")
          print(f"  Total registered tasks: {len(registered_tasks)}")

          # Test 3: Task routing verification
          print("\n[Test 3] Task routing configuration...")
          routes = app.conf.task_routes or {}
          weaviate_tasks = [k for k in routes if 'weaviate' in k]
          print(f"  ✅ {len(weaviate_tasks)} Weaviate tasks routed to dedicated queue")

          # Test 4: Beat schedule verification
          print("\n[Test 4] Beat schedule configuration...")
          beat_schedule = app.conf.beat_schedule or {}
          print(f"  ✅ {len(beat_schedule)} periodic tasks configured")

          print("\n" + "=" * 60)
          print("ALL CELERY INTEGRATION TESTS PASSED")
          print("=" * 60)
          PY

      # ===== STANDARD E2E TESTS (root + ai-chat) =====
      # Note: Playwright's webServer config handles starting the frontend server
      # These tests were previously only run locally via `make test-nightly`
      - name: Run Standard E2E Tests
        if: github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'standard' || github.event.inputs.test_suite == ''
        working-directory: frontend
        run: |
          echo "Running standard E2E tests (root + ai-chat folders)..."
          echo "This includes: github-import, figma, oauth, profile, project, learning, etc."
          npx playwright test 'e2e/*.spec.ts' 'e2e/ai-chat/*.spec.ts' --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      # ===== DEEP E2E TESTS (real AI calls, longer timeouts) =====
      - name: Run Deep E2E Tests - All
        if: github.event.inputs.test_suite == 'all' || github.event.inputs.test_suite == 'deep-all' || github.event.inputs.test_suite == ''
        working-directory: frontend
        run: |
          npx playwright test --project=deep --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      - name: Run Deep E2E Tests - Chat Only
        if: github.event.inputs.test_suite == 'deep-chat'
        working-directory: frontend
        run: |
          npx playwright test e2e/deep/chat*.spec.ts --project=deep --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      - name: Run Deep E2E Tests - Battles Only
        if: github.event.inputs.test_suite == 'deep-battles'
        working-directory: frontend
        run: |
          npx playwright test e2e/deep/battles*.spec.ts --project=deep --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      - name: Run Deep E2E Tests - Learning Only
        if: github.event.inputs.test_suite == 'deep-learning'
        working-directory: frontend
        run: |
          npx playwright test e2e/deep/learning*.spec.ts --project=deep --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      - name: Run Deep E2E Tests - Community Only
        if: github.event.inputs.test_suite == 'deep-community'
        working-directory: frontend
        run: |
          npx playwright test e2e/deep/community*.spec.ts --project=deep --reporter=html
        env:
          TEST_USER_EMAIL: ${{ secrets.E2E_TEST_USER_EMAIL }}
          TEST_USER_PASSWORD: ${{ secrets.E2E_TEST_USER_PASSWORD }}
          VITE_API_PROXY_TARGET: http://127.0.0.1:8000
          VITE_WS_URL: ws://127.0.0.1:8000

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: deep-e2e-test-results-${{ github.run_id }}
          path: |
            frontend/playwright-report/
            frontend/test-results/
          retention-days: 14

      - name: Upload failure videos
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: deep-e2e-failure-videos-${{ github.run_id }}
          path: frontend/test-results/**/*.webm
          retention-days: 7

  notify-on-failure:
    needs: nightly-e2e-tests
    if: failure()
    runs-on: ubuntu-latest
    steps:
      - name: Create issue for failures
        uses: actions/github-script@v7
        with:
          script: |
            const runUrl = `${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId}`;
            const title = `Nightly E2E Tests Failed - ${new Date().toISOString().split('T')[0]}`;
            const body = `## Nightly E2E Test Failure\n\n` +
              `The nightly E2E tests (standard + deep) failed.\n\n` +
              `**Run URL:** ${runUrl}\n\n` +
              `Please investigate and fix any regressions.\n\n` +
              `### Common Causes\n` +
              `- AI response quality degradation\n` +
              `- WebSocket connection issues\n` +
              `- UI changes breaking selectors\n` +
              `- Backend API changes\n` +
              `- GitHub/OAuth integration issues\n`;

            // Check for existing open issue
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'nightly-e2e-failure',
              per_page: 1
            });

            if (issues.data.length === 0) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['nightly-e2e-failure', 'automated']
              });
            } else {
              // Comment on existing issue
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: issues.data[0].number,
                body: `Another failure occurred: ${runUrl}`
              });
            }
