version: '3.9'
services:
  db:
    image: postgres:18.1-alpine
    restart: unless-stopped
    # Increase max_connections from default 100 to handle:
    # - Django web workers (~20 connections)
    # - Celery workers (~20 connections)
    # - Celery beat (~5 connections)
    # - E2E test workers (4 parallel Ã— ~10 each)
    command: postgres -c max_connections=200
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-allthrive_ai}
      POSTGRES_USER: ${POSTGRES_USER:-allthrive}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-allthrive}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-allthrive} -d ${POSTGRES_DB:-allthrive_ai}"]
      interval: 5s
      timeout: 5s
      retries: 5

  redis:
    image: redis/redis-stack-server:latest
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  minio:
    image: minio/minio:latest
    restart: unless-stopped
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  web:
    build: .
    image: allthriveai-backend:latest
    restart: unless-stopped
    stop_grace_period: 30s
    # Run as root for Docker socket access (admin log streaming)
    # Production uses non-root user via Dockerfile USER directive
    user: root
    ports:
      - "8000:8000"
      - "6006:6006"  # Phoenix LLM observability UI
    environment:
      - DEBUG=True
      - ALLOWED_HOSTS=localhost,127.0.0.1,web
      - PHOENIX_HOST=0.0.0.0
      - PHOENIX_PORT=6006
      - DATABASE_URL=postgresql://${POSTGRES_USER:-allthrive}:${POSTGRES_PASSWORD:-allthrive}@db:5432/${POSTGRES_DB:-allthrive_ai}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - REDIS_URL=redis://redis:6379/3
      - CACHE_URL=redis://redis:6379/2
      - GOOGLE_CLIENT_ID=${GOOGLE_CLIENT_ID}
      - GOOGLE_CLIENT_SECRET=${GOOGLE_CLIENT_SECRET}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - GITHUB_CLIENT_ID=${GITHUB_CLIENT_ID}
      - GITHUB_CLIENT_SECRET=${GITHUB_CLIENT_SECRET}
      - LINKEDIN_OAUTH_CLIENT_ID=${LINKEDIN_OAUTH_CLIENT_ID}
      - LINKEDIN_OAUTH_CLIENT_SECRET=${LINKEDIN_OAUTH_CLIENT_SECRET}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MINIO_USE_SSL=false
      - WEAVIATE_URL=http://weaviate:8080
      - STRIPE_PUBLIC_KEY=${STRIPE_PUBLIC_KEY}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_PHONE_NUMBER=${TWILIO_PHONE_NUMBER}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - .:/app
      # Docker socket for admin log streaming (read-only access to container logs)
      - /var/run/docker.sock:/var/run/docker.sock:ro
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_healthy
      weaviate:
        condition: service_healthy
    command: sh /app/scripts/startup.sh

  celery:
    build: .
    image: allthriveai-backend:latest
    restart: unless-stopped
    environment:
      - DEBUG=True
      - DATABASE_URL=postgresql://${POSTGRES_USER:-allthrive}:${POSTGRES_PASSWORD:-allthrive}@db:5432/${POSTGRES_DB:-allthrive_ai}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - REDIS_URL=redis://redis:6379/3
      - CACHE_URL=redis://redis:6379/2
      - WEAVIATE_URL=http://weaviate:8080
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MINIO_USE_SSL=false
      - STRIPE_PUBLIC_KEY=${STRIPE_PUBLIC_KEY}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - TWILIO_ACCOUNT_SID=${TWILIO_ACCOUNT_SID}
      - TWILIO_AUTH_TOKEN=${TWILIO_AUTH_TOKEN}
      - TWILIO_PHONE_NUMBER=${TWILIO_PHONE_NUMBER}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    volumes:
      - .:/app
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
      weaviate:
        condition: service_healthy
    command: celery -A config worker --pool=prefork --concurrency=4 --loglevel=info -Q celery,weaviate
    healthcheck:
      test: ["CMD-SHELL", "celery -A config inspect ping -d celery@$$HOSTNAME"]
      interval: 10s
      timeout: 10s
      retries: 5

  celery-beat:
    build: .
    image: allthriveai-backend:latest
    restart: unless-stopped
    environment:
      - DEBUG=True
      - DATABASE_URL=postgresql://${POSTGRES_USER:-allthrive}:${POSTGRES_PASSWORD:-allthrive}@db:5432/${POSTGRES_DB:-allthrive_ai}
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - REDIS_URL=redis://redis:6379/3
      - CACHE_URL=redis://redis:6379/2
      - WEAVIATE_URL=http://weaviate:8080
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD:-minioadmin}
      - MINIO_USE_SSL=false
    volumes:
      - .:/app
    depends_on:
      celery:
        condition: service_healthy
    command: celery -A config beat --loglevel=info
    healthcheck:
      test: ["CMD-SHELL", "pgrep -f 'celery -A config beat'"]
      interval: 10s
      timeout: 5s
      retries: 3
    container_name: allthriveai_celery-beat_1

  stripe-cli:
    image: stripe/stripe-cli:latest
    restart: unless-stopped
    environment:
      - STRIPE_API_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_DEVICE_NAME=allthrive_docker
    command: listen --forward-to http://web:8000/api/v1/billing/webhooks/stripe/ --skip-verify
    depends_on:
      - web
    profiles:
      - stripe-webhooks

  frontend:
    image: node:20  # Use Debian-based image for better ARM64/AMD64 compatibility
    restart: unless-stopped
    ports:
      - "3000:3000"
    working_dir: /app
    volumes:
      - ./frontend:/app
      - /app/node_modules
    environment:
      - NODE_ENV=development
      # CRITICAL: Vite proxy target for Docker networking
      # Inside Docker, 'web' is the backend service name, NOT localhost
      - VITE_API_PROXY_TARGET=http://web:8000
    depends_on:
      - web
    command: sh -c "npm install --legacy-peer-deps && npm run dev -- --host 0.0.0.0 --port 3000"
    container_name: allthriveai_frontend_1

  prometheus:
    image: prom/prometheus:latest
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3

  grafana:
    image: grafana/grafana:latest
    restart: unless-stopped
    ports:
      - "3001:3000"  # Using 3001 to avoid conflict with frontend
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://localhost:3001
    depends_on:
      - prometheus
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  weaviate:
    image: cr.weaviate.io/semitechnologies/weaviate:1.27.0
    restart: unless-stopped
    ports:
      - "8080:8080"  # REST API
      - "50051:50051"  # gRPC
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai'
      CLUSTER_HOSTNAME: 'node1'
      # Azure OpenAI configuration for vectorization
      AZURE_APIKEY: ${AZURE_OPENAI_API_KEY}
      OPENAI_APIKEY: ${OPENAI_API_KEY}
    volumes:
      - weaviate_data:/var/lib/weaviate
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8080/v1/.well-known/ready"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Redis Agent Memory Server - AI memory layer for chat persistence
  # Provides semantic search, cross-device sync, and AI memory extraction
  agent-memory:
    image: redislabs/agent-memory-server:latest
    restart: unless-stopped
    ports:
      - "8001:8000"  # API server (8001 to avoid conflict with Django)
    environment:
      - REDIS_URL=redis://redis:6379/4
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - DISABLE_AUTH=true  # Disable auth for local dev (enable in production)
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    profiles:
      - agent-memory  # Optional: use `docker compose --profile agent-memory up`

  # Background worker for agent memory (memory extraction, summarization)
  agent-memory-worker:
    image: redislabs/agent-memory-server:latest
    restart: unless-stopped
    environment:
      - REDIS_URL=redis://redis:6379/4
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - LOG_LEVEL=INFO
    command: agent-memory task-worker --concurrency 5
    depends_on:
      redis:
        condition: service_healthy
      agent-memory:
        condition: service_healthy
    profiles:
      - agent-memory  # Optional: use `docker compose --profile agent-memory up`

volumes:
  postgres_data:
  minio_data:
  prometheus_data:
  grafana_data:
  weaviate_data:
